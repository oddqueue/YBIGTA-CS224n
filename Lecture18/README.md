# Ch18: Constituency Parsing, TreeRNNs

# 1. Motivation: Compositionality and Recursion

Compositionality

- word vector ì´ìƒì˜ ë” í° êµ¬ì ˆì— ëŒ€í•œ ê³ ë ¤ì˜ í•„ìš”ì„±ì— ëŒ€í•´ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ì‚¬ëŒë“¤ì€ ëŒ€ê°œ ì´ëŸ¬í•œ í° í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì‘ì€ ìš”ì†Œë“¤ì˜ **semantic composition** ì„ í†µí•´ íŒŒì•…í•œë‹¤.
    
- ì–¸ì–´ëŠ” recursive structureì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì€ cognitiveí•˜ê²ŒëŠ” ë…¼ìŸ ì¤‘ì¸ ì˜ì—­ì´ì§€ë§Œ, ì ì–´ë„ ê·¸ë ‡ë‹¤ê³  í‘œí˜„í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

![Untitled](assets/Untitled.png)

       ğŸ”¼Â ê°€ë ¹ ì–´ë–¤ ëª…ì‚¬êµ¬ëŠ” ë” ì‘ì€ ëª…ì‚¬êµ¬ë¥¼ í¬í•¨í•˜ê³ , ê·¸ ì•ˆì—ë„ ë” ì‘ì€ ëª…ì‚¬êµ¬ê°€ ìˆëŠ” í˜•íƒœ

![Untitled](assets/Untitled1.png)

      ë¬¼ë¡  recursiveì˜ ì •ì˜ëŒ€ë¡œ ì •í™•í•˜ê²Œ ë¬´í•œí•˜ê²Œ recursiveí•˜ì§„ ì•Šê³  nestedë¼ê³  í•˜ê³  ì‹¶ì„ ìˆ˜ ìˆì–´ë„,          

conceptual í•˜ê²Œ recursiveë¼ê³  í•  ìˆ˜ ìˆì„ ê²ƒ!

![Untitled](assets/Untitled2.png)

ğŸ”¼Â consistuency grammar (tree structure!)Â 

# 2. Structure prediction with simple Tree RNN: Parsing

How should we map phrases into a vector space?

ê¸°ì¡´ì— word vetorì„ ë²¡í„° ìŠ¤í˜ì´ìŠ¤ì— ë§¤í•‘í–ˆë˜ ê²ƒì²˜ëŸ¼, ë” ê¸´ êµ¬ì ˆë„ ë§¤í•‘í•´ë³´ì.

- meaning composition rule: ë” í° constituentë‚˜ ë¬¸ì¥ì„ ìœ„í•´ upwardsë¡œ ê³„ì‚°!

ì´ ì‘ì—…ì„ ìœ„í•œ ë‘ ë‹¨ê³„ë¥¼ ìƒê°í•´ ë³´ë©´, 

1. ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì •í™•í•˜ê²Œ ë‹¤ë£¨ê¸° ìœ„í•´ ë¨¼ì € Parsingì„ í•œë‹¤.
2. meaning computationì„ í•œë‹¤.

> Treeêµ¬ì¡°ê°€ ê¸°ì¡´ RNNê³¼ ë‹¤ë¥¸ ì 
> 
> 
> ![Untitled](assets/Untitled3.png)
> 
> ê¸°ì¡´ RNNë„ ì–´ëŠ ì •ë„ì˜ sequenceë¥¼ ë°˜ì˜í•˜ê³  attentionì„ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, tree êµ¬ì¡°ëŠ” ë” ë¶„ëª…í•˜ê²Œ ë‹¨ì–´ë“¤ì´ êµ¬ì™€ ì ˆì„ ì´ë£¨ëŠ” ê³¼ì •ì„ ë°˜ì˜í•˜ê³ , ë”°ë¼ì„œ syntatic structureì— í›¨ì”¬ sensitiveí•˜ë‹¤.
> 

Recursive Neural Networks for Strucrue Prediction 

![Untitled](assets/Untitled4.png)

- ì¸í’‹: ë‘ ê°œì˜ children representation
- ì•„ì›ƒí’‹ :
    1. ***(p)*** ë‘ ê°œ ë…¸ë“œê°€ ë³‘í•©ë  ê²½ìš°ì˜ semantic representation
    2. ***(score)*** ë³‘í•©ëœ ìƒˆë¡œìš´ ë…¸ë“œê°€ ì–¼ë§ˆë‚˜ ê·¸ëŸ´ë“¯í•œì§€ì— ëŒ€í•œ ì ìˆ˜(parse treeì—ì„œ ì¢‹ì€ constituentë¥¼ í˜•ì„±í•˜ëŠ”ê°€)
    
    ğŸ”½Â p ì™€ score ì‹
    

![Untitled](assets/Untitled5.png)

Parsing a sentence with an RNN(greedily)

- greedy parser
    
    ì „ì²´ë¥¼ ê²€í† í•œ ë’¤ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ê²ƒë¶€í„° ë³‘í•©í•´ì„œ ê³„ì‚°í•´ ë‚˜ê°„ë‹¤
    

![Untitled](assets/Untitled6.png)

![Untitled](assets/Untitled7.png)

- Max-Margin Framework
    
    ![Untitled](assets/Untitled8.png)
    
    ![Untitled](assets/Untitled9.png)
    
    ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” max margin objective functionê³¼ ë¹„ìŠ·í•œ í˜•íƒœì¸ë°, ì—¬ê¸°ì—ì„œ A(Xi)ì˜ ì„œì¹˜ êµ¬ì¡°ê°€ greedyì¸ ê²ƒì´ì—ˆìŒ
    

# 3. Backpropagation Through Structure

- Goller&Kuchler(1996)
- ê¸°ë³¸ì ìœ¼ë¡œ ì´ì „ ê°•ì˜ì—ì„œ ë°°ì› ë˜ ë‚´ìš©ê³¼ ë¹„ìŠ·í•˜ë‹¤

![Untitled](assets/Untitled10.png)

1. ê¸°ì¡´  RNNì—ì„œì²˜ëŸ¼, ëª¨ë“  ë…¸ë“œì—ì„œ Wì˜ ë¯¸ë¶„ê°’ì„ êµ¬í•´ì„œ sum up
2. downwardë¡œ ë¯¸ë¶„ê°’ì„ split
3. parentë¡œë¶€í„°ì˜ errorì™€ ë…¸ë“œ ìì‹ ì˜ errorì„ ë”í•œë‹¤
- 2ë²ˆì´ ê¸°ì¡´  backpropagation ê³¼ì¡°ê¸ˆ ë‹¤ë¥¸ ì ì¸ë°,
    
    forward propagationì‹œì— parent nodeê°€ ë‹¤ìŒê³¼ ê°™ì´ 2ê°œ children nodeë¡œ ê³„ì‚°ë˜ë¯€ë¡œ
    
    ![](assets/Untitled13.png)
    
    back propagationì‹œì— ë‹¤ìŒê³¼ ê°™ì´ ê°ê°ì— ëŒ€í•´ splití•´ì•¼ í•œë‹¤.
    
    ![](assets/Untitled14.png)
    

Discussion: Simple TreeRNN

- single matrix TreeRNNìœ¼ë¡œë„ ì¢‹ì€ ì„±ê³¼ê°€ ë‚˜ì˜¤ê¸´ í–ˆì§€ë§Œ, ë” ë³µì¡í•œ ìƒìœ„ì˜ compositionì„ ë‹¤ë£¨ê±°ë‚˜ ê¸´ ë¬¸ì¥ë“¤ì„ parsingí•˜ê¸°ì—ëŠ” ì í•©í•˜ì§€ ì•Šì•˜ë‹¤.
- ì‚¬ì‹¤ìƒ ë‘ ê°€ì§€ ì¸í’‹ ì‚¬ì´ì— interactoin ì´ ì—†ë‹¤.
- í•œ ê°œì˜ weight matrixë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ëª¨ë“  syntatic categories, punctuaion ë“±ì— ëŒ€í•´ ê°™ì€ composition funtionì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤

# 4. More complex TreeRNN units

Syntatically-United RNN (SU-RNN)

- ê¸°ë³¸ syntacticêµ¬ì¡°ì˜ backboneìœ¼ë¡œ symbolic Context-Free Grammarë¥¼ ì‚¬ìš©í•œë‹¤.
- ì´ì— ë”°ë¼ êµ¬ë¶„ëœ syntactic categoriesë¥¼ ì‚¬ìš©í•´ì„œ composition matrixë¥¼ chooseí•œë‹¤.
    
    ì¦‰ ì´ì „ì²˜ëŸ¼ í•œ ê°œì˜ universalí•œ matrixë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì»´í¬ì§€ì…˜ì˜ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¤ë¥¸ matrixë¥¼ ì‚¬ìš©í•œë‹¤.
    
    ![](assets/Untitled15.png)
    
- Compositional Vector Grammar (CVG)
    
    : PCFG + TreeRNN
    
    PCFGë¥¼ ì‚¬ìš©í•´ì„œ, Context-free Grammarë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ ë” ë¹ ë¥´ê²Œ parseí•  ìˆ˜ ìˆë‹¤. 
    
- SU-RNN/CVGë¥¼ í†µí•œ í•™ìŠµì—ì„œì˜ weight matrix ì‹œê°í™”
    
    ![Untitled](assets/Untitled11.png)
    
    ì˜ë¯¸ì ìœ¼ë¡œ ì¤‘ìš”í•œ ê²ƒì— ê°€ì¤‘ì¹˜ê°€ í¬ë‹¤. 
    

Compositionality Through Recursive Matrix-Vector Spaces (MV-RNN)

- ê¸°ì¡´ì—ëŠ” ì•„ë˜ ì‚¬ì§„ì˜ ì™¼ìª½ê³¼ ê°™ì´ ë‘ ë‹¨ì–´ ë²¡í„°ë¥¼ concatí•´ì„œ weight matrixë¥¼ ê³±í•´ì£¼ëŠ” í˜•íƒœì˜€ë‹¤.
    
    í•˜ì§€ë§Œ ì–´ë–¤ ë‹¨ì–´ëŠ” ê·¸ ìì²´ë¡œ ì˜ë¯¸ë¥¼ ê°€ì§€ê¸° ë³´ë‹¤ ë‹¤ë¥¸ ë‹¨ì–´ì— ì–´ë–¤ ì‘ìš©ì„ í•˜ê¸°ë„ í•œë‹¤.
    
    ê°€ë ¹ â€œvery goodâ€ì˜ â€œveryâ€ëŠ” ë’¤ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ê°•í™”í•˜ëŠ” operator ì—­í• ì„í•œë‹¤. 
    
    ì´ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì˜¤ë¥¸ìª½ê³¼ ê°™ì€ ìƒˆë¡œìš´ composition functionì´ ì œì‹œë˜ì—ˆë‹¤. 
    

![](assets/Untitled16.png)

- ë¯¸ë¦¬ ì–´ë–¤ ê²ƒì´  operatorì¸ì§€ ì •í•˜ì§€ ì•Šê³ , ëª¨ë“  ë‹¨ì–´ì™€ êµ¬ê°€ vector meaningê³¼ matrix meaningì„ ê°€ì§„ë‹¤ê³  ì •í•œë‹¤.
    
    ![](assets/Untitled17.png)
    
    ê¸°ì¡´ì˜ ëª¨ë¸ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ vectorëŠ” ë²¡í„°ë¼ë¦¬ concatë˜ì–´ parent ë…¸ë“œì˜ ë²¡í„°ë¥¼ ë§Œë“¤ê²Œ ë˜ê³ , matrixë“¤ì€ concatë˜ì–´ ì´ë¥¼ ì²˜ë¦¬í•˜ëŠ” matrixì™€ ê³±í•´ì ¸ parent ë…¸ë“œì˜ matrixì„ ë§Œë“¤ê²Œ ëœë‹¤.
    
- ë¬¸ì œì 
    1. matrixì˜ ì—°ì‚°ëŸ‰ì´ ì»¤ì„œ word vectorì˜ ì°¨ì›ì„ ì ë‹¹íˆ ì¤„ì—¬ì•¼ í–ˆë‹¤.,
    2. parent nodeì˜ matrixë¥¼ ì–»ëŠ” ì—°ì‚°ì´ ì‹¤ì œë¡œ phraseë¥¼ ì–»ëŠ” ê³¼ì •ì„ ì—°ì‚°í•˜ëŠ” ì¢‹ì€ ë°©ë²•ì€ ì•„ë‹ˆë‹¤.
    

Beyond the bag of words: Sentimental analysis

í…ìŠ¤íŠ¸ì˜ toneì´ ë¶€ì •ì ì¸ì§€, ê¸ì •ì ì¸ì§€, ì¤‘ë¦½ì ì¸ì§€ íŒë‹¨í•˜ëŠ” ê²ƒ

- Stanford Sentiment Treebank (ë°ì´í„°ì…‹)
    
    ![](assets/Untitled12.png)
    
    Â ë¬¸ì¥ì˜ ê¸/ë¶€ì •/ì¤‘ë¦½ ê°ì •ì„ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ labelí•œë‹¤ â†’ ê° ë‹¨ì–´ì™€ êµ¬ì—ë„ ê°ì •ì´ ë¶€ì—¬ë¨
    
     ëª¨ë“  ëª¨ë¸ì—ì„œ ì´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ë†’ì•„ì¡Œë‹¤!
    

Recursive Neural Tensor Network

- ê·¸ë ‡ì§€ë§Œ ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì€  ë¬¸ì œë¥¼ ìœ„í•´ neural tensorì„ ì‚¬ìš©í•œ ëª¨ë¸ì´ ê³ ì•ˆë˜ì—ˆë‹¤.
    
    ![](assets/Untitled18.png)
    
- ë‘ ë²¡í„°ì˜ interaction ì‚¬ì´ì— ê¸°ì¡´ì˜ matrix ê°€ ì•„ë‹Œ 3d tensorë¥¼ ì‚¬ìš©í•´ì„œ ì—°ì‚°í•œë‹¤.
- ê°ì •ë¶„ì„ì—ì„œ ë°˜ì–´ë²•(negating negatives) ì„ ì˜ ë°˜ì˜í•œë‹¤

//

- í•˜ë‚˜ì˜ sequence computation ì´ ì•„ë‹ˆê³  sentenceë§ˆë‹¤ êµ¬ì¡°ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— GPUì—°ì‚° ì— ìš©ì´í•˜ì§€ ì•Šë‹¤.
- ë¬¼ë¦¬í•™ê°™ì€ ë¶„ì•¼ì—ì„œ íŠ¸ë¦¬ êµ¬ì¡°ê°€ ìš©ì´í•˜ê²Œ ì“°ì¸ë‹¤!